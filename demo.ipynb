{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyLPR demo\n",
    "The demo includes running on whole dataset and for a single relation. Next block of code handles imports and defalt arguments for model.\n",
    "- **rules_file** : file where selected rules are saved after training\n",
    "- **rules_file_temp** : file where all rules are saved\n",
    "- **cores**: number of CPU cores used for multiprocessing (None means all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from pylpr.model import LPR_model\n",
    "from pylpr.data import Graph_names\n",
    "import pandas as pd\n",
    "\n",
    "args = Namespace(\n",
    "    rules_file = 'results/umls.npy',\n",
    "    rules_file_temp = 'demo_temp.npy',\n",
    "    solver = 'PULP_CBC_CMD',\n",
    "    iterations = 20,\n",
    "    rules_load = False,\n",
    "    skip_writing = True,\n",
    "    skip_neg = True,\n",
    "    skip_weight = True,\n",
    "    cores = 3,\n",
    "    seed = 12345,\n",
    "    max_length = 4,\n",
    "    column_generation=False\n",
    ")\n",
    "\n",
    "model = LPR_model(\"datasets/UMLS/\", [0.02, 0.03, 0.04, 0.05, 0.0055, 0.06, 0.07, 0.08, 0.09, 0.1], args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "for rel in model.data.relation_to_num.values():\n",
    "    train = sum([len(ends) for _, ends in model.data.get_facts_for_rel(Graph_names.Train, rel)])\n",
    "    valid = sum([len(ends) for _, ends in model.data.get_facts_for_rel(Graph_names.Validate, rel)])\n",
    "    test  = sum([len(ends) for _, ends in model.data.get_facts_for_rel(Graph_names.Test, rel)])\n",
    "    counts[rel] = (train, valid, test)\n",
    "\n",
    "fact_counts = pd.DataFrame(data=counts.values(), index=counts.keys(), columns=['Train', 'Validate', 'Test'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()\n",
    "result = model.predict()\n",
    "\n",
    "pd.DataFrame(data=result.values(), index=result.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single relation\n",
    "Checking number of facts using variable **fact_counts** before trying other relations recommended. Validation dataset is used to calculate entity rank so relations with no facst in validation dataset yield always MRR 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- relation '37': done\n",
      "- neg for relation '37': done\n"
     ]
    }
   ],
   "source": [
    "relation = 37\n",
    "\n",
    "# fit\n",
    "model.rules = model.generate_rules_for_rel(Graph_names.Train, relation)\n",
    "model.rules = model.get_rules_with_updated_neg_freq(relation)\n",
    "model.rules = model.solve_for_rel(relation, model.get_solver())\n",
    "\n",
    "# predict\n",
    "_, mrr, ranks = model.get_mrr_and_ranks(relation, Graph_names.Test)\n",
    "\n",
    "result = {}\n",
    "\n",
    "hits_1 = model.hits_k(ranks, 1)\n",
    "hits_3 = model.hits_k(ranks, 3)\n",
    "hits_10 = model.hits_k(ranks, 10)\n",
    "result[relation] = {'mrr': mrr, 'hits_1': hits_1, 'hits_3': hits_3, 'hits:10': hits_10}\n",
    "\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other\n",
    "\n",
    "method to convert rule to more readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_to_txt(rule):\n",
    "    consequent = model.data.num_to_relation[rule['consequent']]\n",
    "    path = []\n",
    "    for rel in model.get_rule_antecedent(rule):\n",
    "        if model.data.is_inverse(rel):\n",
    "            r = model.data.inv_to_rel(rel)\n",
    "            path.append('R_' + model.data.num_to_relation[r])\n",
    "            continue\n",
    "        path.append(model.data.num_to_relation[rel])\n",
    "            \n",
    "    return [consequent, path, rule['weight'], rule['freq'], rule['neg']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyLPR-venv",
   "language": "python",
   "name": "pylpr-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
